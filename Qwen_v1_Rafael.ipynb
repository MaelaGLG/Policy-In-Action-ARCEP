{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3c1c15a-5bbe-4b1b-878e-4b1286c4a035",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fitz in /opt/conda/lib/python3.12/site-packages (0.0.1.dev2)\n",
      "Requirement already satisfied: configobj in /opt/conda/lib/python3.12/site-packages (from fitz) (5.0.9)\n",
      "Requirement already satisfied: configparser in /opt/conda/lib/python3.12/site-packages (from fitz) (7.1.0)\n",
      "Requirement already satisfied: httplib2 in /opt/conda/lib/python3.12/site-packages (from fitz) (0.22.0)\n",
      "Requirement already satisfied: nibabel in /opt/conda/lib/python3.12/site-packages (from fitz) (5.3.2)\n",
      "Requirement already satisfied: nipype in /opt/conda/lib/python3.12/site-packages (from fitz) (1.9.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.12/site-packages (from fitz) (2.2.3)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (from fitz) (2.2.3)\n",
      "Requirement already satisfied: pyxnat in /opt/conda/lib/python3.12/site-packages (from fitz) (1.6.3)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.12/site-packages (from fitz) (1.15.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/conda/lib/python3.12/site-packages (from httplib2->fitz) (3.2.1)\n",
      "Requirement already satisfied: packaging>=20 in /opt/conda/lib/python3.12/site-packages (from nibabel->fitz) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in /opt/conda/lib/python3.12/site-packages (from nibabel->fitz) (4.12.2)\n",
      "Requirement already satisfied: click>=6.6.0 in /opt/conda/lib/python3.12/site-packages (from nipype->fitz) (8.1.8)\n",
      "Requirement already satisfied: networkx>=2.5 in /opt/conda/lib/python3.12/site-packages (from nipype->fitz) (3.4.2)\n",
      "Requirement already satisfied: prov>=1.5.2 in /opt/conda/lib/python3.12/site-packages (from nipype->fitz) (2.0.1)\n",
      "Requirement already satisfied: pydot>=1.2.3 in /opt/conda/lib/python3.12/site-packages (from nipype->fitz) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in /opt/conda/lib/python3.12/site-packages (from nipype->fitz) (2.9.0.post0)\n",
      "Requirement already satisfied: rdflib>=5.0.0 in /opt/conda/lib/python3.12/site-packages (from nipype->fitz) (6.3.2)\n",
      "Requirement already satisfied: simplejson>=3.8.0 in /opt/conda/lib/python3.12/site-packages (from nipype->fitz) (3.20.1)\n",
      "Requirement already satisfied: traits>=6.2 in /opt/conda/lib/python3.12/site-packages (from nipype->fitz) (7.0.2)\n",
      "Requirement already satisfied: filelock>=3.0.0 in /opt/conda/lib/python3.12/site-packages (from nipype->fitz) (3.17.0)\n",
      "Requirement already satisfied: acres in /opt/conda/lib/python3.12/site-packages (from nipype->fitz) (0.2.0)\n",
      "Requirement already satisfied: etelemetry>=0.3.1 in /opt/conda/lib/python3.12/site-packages (from nipype->fitz) (0.3.1)\n",
      "Requirement already satisfied: looseversion!=1.2 in /opt/conda/lib/python3.12/site-packages (from nipype->fitz) (1.3.0)\n",
      "Requirement already satisfied: puremagic in /opt/conda/lib/python3.12/site-packages (from nipype->fitz) (1.28)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas->fitz) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas->fitz) (2025.1)\n",
      "Requirement already satisfied: lxml>=4.3 in /opt/conda/lib/python3.12/site-packages (from pyxnat->fitz) (5.3.1)\n",
      "Requirement already satisfied: requests>=2.20 in /opt/conda/lib/python3.12/site-packages (from pyxnat->fitz) (2.32.3)\n",
      "Requirement already satisfied: pathlib>=1.0 in /opt/conda/lib/python3.12/site-packages (from pyxnat->fitz) (1.0.1)\n",
      "Requirement already satisfied: ci-info>=0.2 in /opt/conda/lib/python3.12/site-packages (from etelemetry>=0.3.1->nipype->fitz) (0.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.2->nipype->fitz) (1.17.0)\n",
      "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in /opt/conda/lib/python3.12/site-packages (from rdflib>=5.0.0->nipype->fitz) (0.6.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests>=2.20->pyxnat->fitz) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests>=2.20->pyxnat->fitz) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests>=2.20->pyxnat->fitz) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests>=2.20->pyxnat->fitz) (2025.1.31)\n",
      "Requirement already satisfied: pymupdf in /opt/conda/lib/python3.12/site-packages (1.25.3)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.12/site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.12/site-packages (from torch) (2025.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.12/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.12/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.12/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.12/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.12/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.12/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /opt/conda/lib/python3.12/site-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.12/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /opt/conda/lib/python3.12/site-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Collecting git+https://github.com/huggingface/transformers\n",
      "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-ngp8_c1j\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-ngp8_c1j\n",
      "  Resolved https://github.com/huggingface/transformers to commit e3d99ec2f58e0e2a4df6b2b41152fdfb3f92a52f\n",
      "  Installing build dependencies ... \u001b[?2done\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25done\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25done\n",
      "\u001b[?25hRequirement already satisfied: accelerate in /opt/conda/lib/python3.12/site-packages (1.4.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from transformers==4.50.0.dev0) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /opt/conda/lib/python3.12/site-packages (from transformers==4.50.0.dev0) (0.29.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.12/site-packages (from transformers==4.50.0.dev0) (2.2.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from transformers==4.50.0.dev0) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.12/site-packages (from transformers==4.50.0.dev0) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.12/site-packages (from transformers==4.50.0.dev0) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from transformers==4.50.0.dev0) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.12/site-packages (from transformers==4.50.0.dev0) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.12/site-packages (from transformers==4.50.0.dev0) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.12/site-packages (from transformers==4.50.0.dev0) (4.67.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.12/site-packages (from accelerate) (6.1.1)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/conda/lib/python3.12/site-packages (from accelerate) (2.6.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.50.0.dev0) (2025.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.50.0.dev0) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.1.5)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->transformers==4.50.0.dev0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests->transformers==4.50.0.dev0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests->transformers==4.50.0.dev0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests->transformers==4.50.0.dev0) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: qwen-vl-utils in /opt/conda/lib/python3.12/site-packages (0.0.10)\n",
      "Requirement already satisfied: av in /opt/conda/lib/python3.12/site-packages (from qwen-vl-utils) (14.1.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from qwen-vl-utils) (24.2)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.12/site-packages (from qwen-vl-utils) (11.1.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from qwen-vl-utils) (2.32.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->qwen-vl-utils) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests->qwen-vl-utils) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests->qwen-vl-utils) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests->qwen-vl-utils) (2025.1.31)\n",
      "Requirement already satisfied: langdetect in /opt/conda/lib/python3.12/site-packages (1.0.9)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.12/site-packages (from langdetect) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "get_ipython().system('pip install fitz')\n",
    "get_ipython().system('pip install pymupdf')\n",
    "get_ipython().system('pip install torch')\n",
    "get_ipython().system('pip install git+https://github.com/huggingface/transformers accelerate')\n",
    "get_ipython().system('pip install qwen-vl-utils')\n",
    "get_ipython().system('pip install langdetect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28422c4a-2698-4bc5-80a0-b8f2d05140c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:06<00:00,  1.73s/it]\n",
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📄 Processing PDF: https://arxiv.org/pdf/2211.02001.pdf\n",
      "\n",
      "🔍 Processing: What are the carbon emissions linked to AI training?\n",
      "\n",
      "🔍 Analyzing Chunk 1/5...\n",
      "\n",
      "🔍 Analyzing Chunk 2/5...\n",
      "\n",
      "🔍 Analyzing Chunk 3/5...\n",
      "\n",
      "🔍 Analyzing Chunk 4/5...\n",
      "\n",
      "🔍 Analyzing Chunk 5/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/transformers/generation/utils.py:2109: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📄 Processing PDF: https://arxiv.org/pdf/2304.03271\n",
      "\n",
      "🔍 Processing: What are the carbon emissions linked to AI training?\n",
      "\n",
      "🔍 Analyzing Chunk 1/6...\n",
      "\n",
      "🔍 Analyzing Chunk 2/6...\n",
      "\n",
      "🔍 Analyzing Chunk 3/6...\n",
      "\n",
      "🔍 Analyzing Chunk 4/6...\n",
      "\n",
      "🔍 Analyzing Chunk 5/6...\n",
      "\n",
      "🔍 Analyzing Chunk 6/6...\n",
      "\n",
      "📄 Processing PDF: https://advanced.onlinelibrary.wiley.com/doi/epdf/10.1002/advs.202100707\n",
      "\n",
      "🔍 Processing: What are the carbon emissions linked to AI training?\n",
      "\n",
      "🔍 Analyzing Chunk 1/1...\n",
      "         PDF Name                                           Question  \\\n",
      "0  2211.02001.pdf  What are the carbon emissions linked to AI tra...   \n",
      "1      2304.03271  What are the carbon emissions linked to AI tra...   \n",
      "2  advs.202100707  What are the carbon emissions linked to AI tra...   \n",
      "\n",
      "                                             Summary  \n",
      "0  Summarize the following text in about 100 word...  \n",
      "1  Summarize the following text in about 100 word...  \n",
      "2  Summarize the following text in about 100 word...  \n",
      "\n",
      "⏱️ Total execution time: 8.60 minutes\n"
     ]
    }
   ],
   "source": [
    "# Required libraries\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import requests\n",
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import pandas as pd  # 📊 Import pandas for table display\n",
    "from langdetect import detect\n",
    "from pathlib import Path\n",
    "\n",
    "# Track total execution time\n",
    "overall_start = time.time()\n",
    "\n",
    "# Step 1: Set up the model\n",
    "model_name = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, \n",
    "    torch_dtype=torch.float16, \n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Step 2: Define multiple PDF URLs\n",
    "pdf_urls = [\n",
    "    \"https://arxiv.org/pdf/2211.02001.pdf\",  # Add more PDFs here\n",
    "    \"https://arxiv.org/pdf/2304.03271\",\n",
    "    \"https://advanced.onlinelibrary.wiley.com/doi/epdf/10.1002/advs.202100707\",\n",
    "]\n",
    "\n",
    "# Step 3: Define the single question\n",
    "question = \"What are the carbon emissions linked to AI training?\"\n",
    "\n",
    "# Step 4: Extract text from PDFs\n",
    "def extract_text_from_pdf(pdf_path, max_pages=1, chunk_size=800):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text_chunks = []\n",
    "    text = \"\"\n",
    "    for i, page in enumerate(doc):\n",
    "        if i >= max_pages:\n",
    "            break\n",
    "        text += page.get_text()\n",
    "        while len(text) > chunk_size:\n",
    "            text_chunks.append(text[:chunk_size + 300])  # Overlap for coherence\n",
    "            text = text[chunk_size:]\n",
    "    text_chunks.append(text)\n",
    "    return text_chunks\n",
    "\n",
    "# Step 5: Generate answers\n",
    "def generate_answer(question, text_chunks):\n",
    "    all_responses = []\n",
    "    for i, chunk in enumerate(text_chunks):\n",
    "        print(f\"\\n🔍 Analyzing Chunk {i+1}/{len(text_chunks)}...\")\n",
    "\n",
    "        input_text = (\n",
    "            f\"Context: {chunk}\\n\"\n",
    "            f\"Question: {question}\\n\"\n",
    "            \"Please provide a short, precise answer focusing on numerical data only. \"\n",
    "            \"If no relevant information is found, reply with 'No data available'.\\n\"\n",
    "        )\n",
    "        inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            generated_ids = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=32,  \n",
    "                num_beams=5,    \n",
    "                temperature=0.3,\n",
    "                no_repeat_ngram_size=2,\n",
    "                early_stopping=True\n",
    "            )\n",
    "\n",
    "        response = tokenizer.decode(generated_ids[0], skip_special_tokens=True).strip()\n",
    "        all_responses.append(response)\n",
    "\n",
    "    return all_responses\n",
    "\n",
    "# Step 6: Extract key sentences with proper number handling\n",
    "def extract_key_sentences(responses):\n",
    "    key_sentences = []\n",
    "    for response in responses:\n",
    "        if detect(response) == 'en':\n",
    "            sentences = response.split('. ')\n",
    "            for sentence in sentences:\n",
    "                if re.search(r'\\b\\d+(\\.\\d+)?\\b', sentence):\n",
    "                    if any(keyword in sentence.lower() for keyword in [\"co2\", \"carbon dioxide\", \"emission\", \"tonnes\", \"kg\",\"co2eq\",\"carbon footprint\",\"bloom\",\"training\"]):\n",
    "                        sentence = re.sub(r'(Question|Output Format|Please provide).*?\\. ', '', sentence, flags=re.IGNORECASE)\n",
    "                        sentence = re.sub(r'\\s+', ' ', sentence).strip()\n",
    "                        key_sentences.append(sentence)\n",
    "    return key_sentences\n",
    "\n",
    "\n",
    "# Step 7: Summarize extracted answers\n",
    "def summarize_responses(responses):\n",
    "    summary_text = \" \".join(responses)\n",
    "    summary_prompt = (\n",
    "        f\"Summarize the following text in about 100 words, focusing on CO2 emissions and numerical data:\\n\"\n",
    "        f\"{summary_text}\\n\"\n",
    "    )\n",
    "    summary_inputs = tokenizer(summary_prompt, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        summary_ids = model.generate(\n",
    "            **summary_inputs,\n",
    "            max_new_tokens=150,\n",
    "            num_beams=5,\n",
    "            temperature=0.3,\n",
    "            no_repeat_ngram_size=2,\n",
    "            early_stopping=True\n",
    "        )\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True).strip()\n",
    "    summary = re.sub(r'(Question|Output Format|Please provide).*?\\. ', '', summary, flags=re.IGNORECASE)\n",
    "    summary = re.sub(r'\\s+', ' ', summary).strip()\n",
    "    return summary\n",
    "\n",
    "# Step 9: Process each PDF and store data\n",
    "pdf_data = []\n",
    "\n",
    "for pdf_url in pdf_urls:\n",
    "    print(f\"\\n📄 Processing PDF: {pdf_url}\")\n",
    "\n",
    "    # Download PDF\n",
    "    pdf_name = pdf_url.split(\"/\")[-1]\n",
    "    response = requests.get(pdf_url)\n",
    "    with open(pdf_name, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "    # Extract text\n",
    "    text_chunks = extract_text_from_pdf(pdf_name)\n",
    "\n",
    "    print(f\"\\n🔍 Processing: {question}\")\n",
    "    \n",
    "    # Generate and process responses\n",
    "    responses = generate_answer(question, text_chunks)\n",
    "    filtered_responses = extract_key_sentences(responses)\n",
    "    summary = summarize_responses(filtered_responses)  # Get summary instead of top 10\n",
    "\n",
    "    # Store results\n",
    "    pdf_data.append([pdf_name, question, summary])\n",
    "\n",
    "    # Remove the downloaded PDF to save space\n",
    "    os.remove(pdf_name)\n",
    "\n",
    "# Convert to DataFrame and save\n",
    "df_results = pd.DataFrame(pdf_data, columns=[\"PDF Name\", \"Question\", \"Summary\"])\n",
    "\n",
    "print(df_results)\n",
    "\n",
    "# End timing\n",
    "overall_end = time.time()\n",
    "total_duration = overall_end - overall_start\n",
    "print(f\"\\n⏱️ Total execution time: {total_duration / 60:.2f} minutes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d12d2ba-3954-4fe0-97f4-21b3ad48e396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Results saved at: /home/onyxia/work/AI_Training_Emissions_Summary.csv\n"
     ]
    }
   ],
   "source": [
    "# Define a safe directory\n",
    "save_path = \"/data\" if os.path.exists(\"/data\") else os.getcwd()  # Fallback to the current working directory\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "# Define the file path\n",
    "csv_file = os.path.join(save_path, \"AI_Training_Emissions_Summary.csv\")\n",
    "\n",
    "# Export the DataFrame\n",
    "df_results.to_csv(csv_file, index=False)\n",
    "\n",
    "print(f\"✅ Results saved at: {csv_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5af806c8-c7fb-4ff4-8e09-dd84309380fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         PDF Name                                              Question  \\\n",
      "0  2211.02001.pdf  What are the carbon emissions linked to AI training?   \n",
      "1      2304.03271  What are the carbon emissions linked to AI training?   \n",
      "2  advs.202100707  What are the carbon emissions linked to AI training?   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Summary  \n",
      "0  Summarize the following text in about 100 words, focusing on CO2 emissions and numerical data: In the present article, we aim to quantify the carbon footprint of BLOOM, a 176-billion parameter language model, across its life cycle We estimate that BLOOM’s ﬁnal training emitted approximately 24.7 tonnes of CO2eq if we consider only the dynamic power consumption, and 50.5 tonnes if we account for all processes ranging from equipment manufacturing to energy-based operational consumption We conclude with a discussion regarding the difﬁculty of precisely estimating the carbon footprint of ML models and future research directions that can contribute towards improving carbon emissions reporting. 1 Introduction Climate change is one of our generation’s biggest challenges, impacting ecosystems and livelihoods across the world; estimating and reducing our carbon emissions is an important part of mitigating its impacts [23] According to recent estimates, the global CO2 emissions of the information and communications technology (ICT) sector account for around 2% of global CO2 emissions, but this ﬁgure is hard to estimate precisely given the distributed nature of global computing infrastructure [14, 22, 7] We conclude with a discussion about the carbon emissions of different LLMs as well as the BigScience workshop overall, and propose directions for future work to both quantify and report these emissions. 2 Related Work There are different aspects of the environmental impact of computing in general and machine learning in particular that are relevant to our study; we brieﬂy describe existing relevant work in the paragraphs below. Empirical Studies on ML CO2 Emissions Most of the existing work in this area has been done on estimating the CO2 emissions incurred during model training Starting with the seminal work of Strubell et al., who looked at the arXiv:2211.02001v1 [cs.LG] 3 Nov 2022 The paper \"Energy and Carbon Implications of Modern Deep Learning Workflows\" estimates that training a large language model can emit up to 880,0 To summarize the key points about carbon footprints of language models: - BLoOM model's final training emissions: - Dynamic power usage: ~25 tCO2e - Full lifecycle (incl. manufacturing, energy): ~51 tC - Estimated global ICT sector emissions (approx.): 0-2% - Related work: Most studies focus on training phase emissions. - Proposed future directions: Better quantification and reporting of emissions. The text does not provide exact figures for other AI models' emissions but discusses the challenges and need for more precise estimates. The closest relevant data mentioned is the upper end of a range for training large LMs, which can reach ~8.8 million kg (8,8  \n",
      "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Summarize the following text in about 100 words, focusing on CO2 emissions and numerical data: For example, training the GPT-3 language model in Microsoft’s state-of-the-art U.S In this paper, we provide a principled methodology to estimate the water footprint of AI, and also discuss the unique spatial-temporal diversities of AI’s runtime water efficiency. Finally, we highlight the necessity of holistically addressing water footprint along with carbon footprint to enable truly sustainable AI. 1 Introduction • “Water is a finite resource, and every drop matters.” — Facebook (now Meta) Sustainability Report 2020 [1]. • “Fresh, clean water is one of the most precious resources on Earth .. As a result, AI’s carbon footprint has been undergoing scrutiny, driving the recent progress in AI carbon efficiency [6,7]. However, AI’s water footprint — many millions of liters of freshwater consumed for cooling the servers and for electricity generation — has largely remained under the radar and keeps escalating Even excluding the water usage in leased third-party colocation facilities, Google’s self-owned data centers alone directly withdrew 29 b 2The detailed difference between water withdrawal and water consumption is presented in Section 2.1. 1 arXiv:2304.03271v4 2The detailed difference between water withdrawal and water consumption is presented in Section 2.1. 1 arXiv:2304.03271v4 [cs.LG] 15 Jan 2025 Question: What are the carbon emissions linked to AI training? Please provide a short, precise answer focusing on numerical data only The text discusses the underappreciated water足迹 of artificial intelligence (AI), particularly in the context of training large language models. It highlights that while carbon footprints are increasingly scrutinized, the substantial freshwater consumption for AI operations, including cooling and electricity, has received less attention and continues to grow. Notably, even without considering external data center usage, self-operated Google facilities alone consumed 39 billion liters (3.9 million cubic meters) of water. The paper emphasizes the need for a comprehensive approach to sustainability, addressing both water and carbon impacts. 关于AI训练的碳排放，文中提到，尽管碳足迹正受到越来越多的关注，但AI操作中的大量淡水消耗（包括冷却和电力生产）却一直被忽视  \n",
      "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Summarize the following text in about 100 words, focusing on CO2 emissions and numerical data: If no relevant information is found, reply with 'No data available'. 1200 kg of CO2 per hour for a single GPU training a large language model. Question type: Numerical data extraction Answer format: [ Based on the provided text, here is the summary with the numerical information extracted: [ The text indicates that a singular GPU used for training substantial language models produces CO₂ emissions at a rate of 0.2 kg per minute, given that there are 60 minutes in an hour. ] [ Explanation: The original text mentions \"per hour,\" so we converted the hourly rate to a per-minute rate for more granular understanding. The calculation is as follows: \\( \\frac{2 \\, \\text{kg/hour}}{6} = 2/6 \\) kg/minute, which simplifies to approximately 33.3 kg/half-hour, but the closest simple fraction that matches the given data is 40  \n"
     ]
    }
   ],
   "source": [
    "# Ensure all text is visible\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "# Print the summary content\n",
    "print(df_results[[\"PDF Name\", \"Question\", \"Summary\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4099686-3d61-419a-8f2a-f4d3fd015d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔎 Analyzing Sentence: Summarize the following text in about 100 words, focusing on CO2 emissions and numerical data: In the present article, we aim to quantify the carbon footprint of BLOOM, a 176-billion parameter language model, across its life cycle We estimate that BLOOM’s ﬁnal training emitted approximately 24.7 tonnes of CO2eq if we consider only the dynamic power consumption, and 50.5 tonnes if we account for all processes ranging from equipment manufacturing to energy-based operational consumption We conclude with a discussion regarding the difﬁculty of precisely estimating the carbon footprint of ML models and future research directions that can contribute towards improving carbon emissions reporting.\n",
      "✅ Model Found: BLOOM with Emission: 24.7 Tonnes\n",
      "\n",
      "🔎 Analyzing Sentence: Summarize the following text in about 100 words, focusing on CO2 emissions and numerical data: For example, training the GPT-3 language model in Microsoft’s state-of-the-art U.S In this paper, we provide a principled methodology to estimate the water footprint of AI, and also discuss the unique spatial-temporal diversities of AI’s runtime water efficiency.\n",
      "⚠️ Model mentioned but no emissions found.\n",
      "\n",
      "📊 CO2 Emissions by Model with Context:\n",
      "         PDF Name Model Name  CO2 Emission (Tonnes)  \\\n",
      "0  2211.02001.pdf      BLOOM                   24.7   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Context  \n",
      "0  Summarize the following text in about 100 words, focusing on CO2 emissions and numerical data: In the present article, we aim to quantify the carbon footprint of BLOOM, a 176-billion parameter language model, across its life cycle We estimate that BLOOM’s ﬁnal training emitted approximately 24.7 tonnes of CO2eq if we consider only the dynamic power consumption, and 50.5 tonnes if we account for all processes ranging from equipment manufacturing to energy-based operational consumption We conclude with a discussion regarding the difﬁculty of precisely estimating the carbon footprint of ML models and future research directions that can contribute towards improving carbon emissions reporting.  \n"
     ]
    }
   ],
   "source": [
    "# List of model names to look for (modify this as needed)\n",
    "model_names = [\n",
    "    \"BLOOM\",\n",
    "    \"GPT-3\",\n",
    "    \"T5\",\n",
    "    \"BERT\",\n",
    "    \"XLNet\",\n",
    "    \"RoBERTa\",\n",
    "    \"GPT-2\",\n",
    "    \"Transformer-XL\",\n",
    "    \"Albert\",\n",
    "    \"Megatron\"\n",
    "]\n",
    "\n",
    "# Function to extract model names and CO2 emissions from summaries\n",
    "def extract_model_emissions_from_summary(df, model_names):\n",
    "    model_emissions = []\n",
    "\n",
    "    # Improved pattern to capture multiple emissions per model\n",
    "    pattern = re.compile(\n",
    "        r\"(?P<model>\" + \"|\".join(model_names) + r\").*?(?:approximately|around|about)?\\s?(?P<emission>\\d+(\\.\\d+)?)\\s?(?:tonnes|tonne|t)\\s?(?:CO2|CO2eq|CO₂)?\",\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        pdf_name = row[\"PDF Name\"]\n",
    "        summary = row[\"Summary\"]\n",
    "\n",
    "        if isinstance(summary, str):  # Ensure valid text\n",
    "            sentences = re.split(r'(?<=[.!?]) +', summary)  # Sentence splitting\n",
    "            \n",
    "            for sentence in sentences:\n",
    "                if any(model in sentence for model in model_names):  # Check if sentence mentions a model\n",
    "                    print(f\"\\n🔎 Analyzing Sentence: {sentence}\")\n",
    "\n",
    "                    matches = pattern.findall(sentence)  # Extract emissions\n",
    "                    if matches:\n",
    "                        for match in matches:\n",
    "                            model = match[0]  # Extracted model name\n",
    "                            emission = float(match[1])  # Extracted CO2 emission value\n",
    "                            model_emissions.append({\n",
    "                                \"PDF Name\": pdf_name,\n",
    "                                \"Model Name\": model,\n",
    "                                \"CO2 Emission (Tonnes)\": emission,\n",
    "                                \"Context\": sentence\n",
    "                            })\n",
    "                            print(f\"✅ Model Found: {model} with Emission: {emission} Tonnes\")\n",
    "                    else:\n",
    "                        print(\"⚠️ Model mentioned but no emissions found.\")\n",
    "    \n",
    "    return model_emissions\n",
    "\n",
    "# Extract model emissions from the summary column\n",
    "model_emissions_list = extract_model_emissions_from_summary(df_results, model_names)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_emissions = pd.DataFrame(model_emissions_list)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"\\n📊 CO2 Emissions by Model with Context:\")\n",
    "print(df_emissions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a71f8c5c-3137-4527-b381-32d6ef598507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CO2 emissions data saved at: /home/onyxia/work/CO2_Emissions_By_Model.csv\n"
     ]
    }
   ],
   "source": [
    "# Define a safe directory\n",
    "save_path = \"/data\" if os.path.exists(\"/data\") else os.getcwd()  # Fallback to the current working directory\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "# Define the file path\n",
    "csv_file = os.path.join(save_path, \"CO2_Emissions_By_Model.csv\")\n",
    "\n",
    "# Export the DataFrame\n",
    "df_emissions.to_csv(csv_file, index=False)\n",
    "\n",
    "print(f\"✅ CO2 emissions data saved at: {csv_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d211a8a0-872f-44d0-b502-205b21080b5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
